# -*- coding: utf-8 -*-
"""NeuralNetworkClassification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11-0K_vjKv8Yc6TnFzqtkJdTpmgcuIBUu
"""
import nltk
import pandas as pd
import numpy as np
import torch
from torch import nn
from torch.utils.data import Dataset, DataLoader
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, mean_squared_error, r2_score
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
import seaborn as sns
import re
import matplotlib.pyplot as plt

def clean_text(text):
    text = str(text).lower()
    text = re.sub(r"http\S+|www\S+|@\w+|#\w+|[^a-z\s]", "", text)
    tokens = word_tokenize(text)
    tokens = [word for word in tokens if word not in stopwords.words("english")]
    return " ".join(tokens) if tokens else "empty"

class SentimentDataset(Dataset):
    def __init__(self, X, y):
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.long)

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

class ClassificationNN(nn.Module):
    def __init__(self, input_dim):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 3)
        )

    def forward(self, x):
        return self.net(x)

def load_data(file, use_nlp=False, vectorizer=None, scaler=None, fit=True):
    df = pd.read_csv(file)
    df['sentiment'] = df['sentiment'].map({'negative': 0, 'neutral': 1, 'positive': 2})
    df.dropna(inplace=True)
    y = df['sentiment'].values
    if 'candidate' not in df.columns:
        if 'train' in file:
            orig_file = 'train.csv'
        elif 'val' in file or 'valid' in file:
            orig_file = 'val.csv'
        elif 'test' in file:
            orig_file = 'test.csv'
        else:
            raise ValueError("Unknown dataset type. Cannot locate candidate column.")

        df_orig = pd.read_csv(orig_file)
        df['candidate'] = df_orig.loc[df.index, 'candidate']

    if use_nlp:
        df['clean_tweet'] = df['tweet_text'].apply(clean_text)
        if fit:
            vectorizer = TfidfVectorizer(max_features=5000)
            X_text = vectorizer.fit_transform(df['clean_tweet']).toarray()
        else:
            X_text = vectorizer.transform(df['clean_tweet']).toarray()
    else:
        X_text = np.array([]).reshape(len(df), 0)

    if 'candidate' in df.columns:
        X_num = df[['likes', 'retweets', 'candidate']].values
        candidate_values = X_num[:, -1]
        if fit:
            scaler = StandardScaler()
            X_num_scaled = scaler.fit_transform(X_num[:, :-1])
        else:
            X_num_scaled = scaler.transform(X_num[:, :-1])
        X = np.hstack((X_num_scaled, X_text)).astype(np.float32)
    else:
        X_num = df[['likes', 'retweets']].values
        candidate_values = []
        if fit:
            scaler = StandardScaler()
            X_num_scaled = scaler.fit_transform(X_num)
        else:
            X_num_scaled = scaler.transform(X_num)
        X = np.hstack((X_num_scaled, X_text)).astype(np.float32)

    return X, y, vectorizer, scaler, df, candidate_values

def train_model(X_train, y_train, X_val, y_val, X_test, y_test, input_dim, epochs=30, lr=0.001):
    model = ClassificationNN(input_dim)
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    train_loader = DataLoader(SentimentDataset(X_train, y_train), batch_size=32, shuffle=True)

    train_losses, val_accuracies, test_accuracies = [], [], []

    for epoch in range(epochs):
        model.train()
        epoch_loss = 0.0
        for X_batch, y_batch in train_loader:
            optimizer.zero_grad()
            preds = model(X_batch)
            loss = criterion(preds, y_batch)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()

        avg_loss = epoch_loss / len(train_loader)
        train_losses.append(avg_loss)

        model.eval()
        with torch.no_grad():
            logits_val = model(torch.tensor(X_val, dtype=torch.float32))
            logits_test = model(torch.tensor(X_test, dtype=torch.float32))
            val_preds = torch.argmax(logits_val, dim=1).numpy()
            test_preds = torch.argmax(logits_test, dim=1).numpy()
            val_acc = np.mean(val_preds == y_val) * 100
            test_acc = np.mean(test_preds == y_test) * 100
            val_accuracies.append(val_acc)
            test_accuracies.append(test_acc)

        print(f"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}, Val Accuracy: {val_acc:.2f}%")

    return model, train_losses, val_accuracies, test_accuracies

def evaluate_model(model, X, y, candidates, file_name):
    model.eval()
    with torch.no_grad():
        logits = model(torch.tensor(X, dtype=torch.float32))
        preds = torch.argmax(logits, dim=1).numpy()

    accuracy = accuracy_score(y, preds) * 100
    precision, recall, f1, _ = precision_recall_fscore_support(y, preds, average='weighted')
    rmse = mean_squared_error(y, preds)
    r2 = r2_score(y, preds)
    cm = confusion_matrix(y, preds)

    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=['negative', 'neutral', 'positive'], yticklabels=['negative', 'neutral', 'positive'])
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.title(f"Confusion Matrix - {file_name}")
    plt.show()

    print(f"\nFinal Evaluation Metrics for {file_name}:")
    print(f"Accuracy: {accuracy:.2f}% | Precision: {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f}| MSE:{rmse:.4f}|R^2 error:{r2:.4f}")

    candidate_accuracy = {}
    if len(candidates) > 0:
        candidates = np.array(candidates)
        unique_candidates = np.unique(candidates)

        for candidate in unique_candidates:
            indices = np.where(candidates == candidate)[0]
            if len(indices) > 0:
                acc = accuracy_score(np.array(y)[indices], preds[indices]) * 100
                candidate_accuracy[candidate] = acc
                print(f"Accuracy for {candidate}: {acc:.2f}%")

        avg_candidate_accuracy = np.mean(list(candidate_accuracy.values()))
        print(f"Average Accuracy per Candidate: {avg_candidate_accuracy:.2f}%")
    else:
        avg_candidate_accuracy = None

    return accuracy, rmse, r2, candidate_accuracy, avg_candidate_accuracy

def plot_training_curves(train_losses, val_accuracies,test_accuracies):
    epochs = range(1, len(train_losses) + 1)
    plt.figure(figsize=(18, 5))

    plt.subplot(1, 3, 1)
    plt.plot(epochs, train_losses, label='Training Loss', marker='o')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Training Loss per Epoch')
    plt.grid(True)
    plt.legend()

    plt.subplot(1, 3, 2)
    plt.plot(epochs, val_accuracies, label='Validation Accuracy', color='green', marker='o')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy (%)')
    plt.title('Validation Accuracy per Epoch')
    plt.grid(True)
    plt.legend()

    plt.subplot(1, 3, 3)
    plt.plot(epochs, test_accuracies, label='Test Accuracy', color='red', marker='o')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy (%)')
    plt.title('Test Accuracy per Epoch')
    plt.grid(True)
    plt.legend()

    plt.tight_layout()
    plt.show()

results = []
all_candidate_accuracies = {}
def run_and_store(label, train_file, val_file, test_file, use_nlp):
    print(f"\n== {label} ==")
    X_train, y_train, vectorizer, scaler, _, _ = load_data(train_file, use_nlp, fit=True)
    X_val, y_val, _, _, val_df, val_candidates = load_data(val_file, use_nlp, vectorizer, scaler, fit=False)
    X_test, y_test, _, _, test_df, test_candidates = load_data(test_file, use_nlp, vectorizer, scaler, fit=False)

    model, train_losses, val_accuracies, test_accuracies = train_model(X_train, y_train, X_val, y_val, X_test, y_test, input_dim=X_train.shape[1])

    acc_val, rmse_val, r2_val, val_cand_accs, avg_val_cand_acc = evaluate_model(model, X_val, y_val, val_candidates, label + " - Validation")
    acc_test, rmse_test, r2_test, test_cand_accs, avg_test_cand_acc = evaluate_model(model, X_test, y_test, test_candidates, label + " - Test")

    results.append({
        'Run': label,
        'RMSE': rmse_test,
        'R²': r2_test,
        'Accuracy': acc_test,
        'Avg Candidate Accuracy': avg_test_cand_acc
    })
    all_candidate_accuracies[label] = test_cand_accs
    plot_training_curves(train_losses, val_accuracies, test_accuracies)

run_and_store("Unprocessed + NLP", "train.csv", "val.csv", "test.csv", use_nlp=True)
run_and_store("Preprocessed + NLP", "train_preprocessed.csv", "val_preprocessed.csv", "test_preprocessed.csv", use_nlp=True)
run_and_store("Unprocessed - NLP", "train.csv", "val.csv", "test.csv", use_nlp=False)
run_and_store("Preprocessed - NLP", "train_preprocessed.csv", "val_preprocessed.csv", "test_preprocessed.csv", use_nlp=False)

metrics_df = pd.DataFrame(results)
metrics_df.to_csv("all_model_errors.csv", index=False)

plt.figure(figsize=(10, 6))
bar_width = 0.35
x = np.arange(len(metrics_df))

plt.bar(x - bar_width/2, metrics_df['RMSE'], width=bar_width, label='MSE')
plt.bar(x + bar_width/2, metrics_df['R²'], width=bar_width, label='R²')

plt.xticks(x, metrics_df['Run'], rotation=45)
plt.ylabel("Error Metric Value")
plt.title("Model Error Comparison (Test Set)")
plt.legend()
plt.tight_layout()
plt.grid(True, linestyle='--', alpha=0.6)
plt.show()

def plot_all_candidate_accuracies(all_cand_accs):
    print("\n=== Candidate-wise Accuracy by Dataset ===")
    all_candidates = sorted(set(c for d in all_cand_accs.values() for c in d))

    # Print table
    header = ["Candidate"] + list(all_cand_accs.keys())
    row_format = "{:<15}" + "{:<15}" * len(all_cand_accs)
    print(row_format.format(*header))

    for candidate in all_candidates:
        row = [candidate]
        for dataset in all_cand_accs:
            acc = all_cand_accs[dataset].get(candidate, "N/A")
            row.append(f"{acc:.2f}%" if isinstance(acc, float) else acc)
        print(row_format.format(*row))

    x = np.arange(len(all_candidates))
    width = 0.8 / len(all_cand_accs)

    plt.figure(figsize=(10, 6))
    for i, (label, acc_dict) in enumerate(all_cand_accs.items()):
        accs = [acc_dict.get(candidate, 0) for candidate in all_candidates]
        plt.bar(x + i * width, accs, width=width, label=label)

    plt.xlabel("Candidate")
    plt.ylabel("Accuracy (%)")
    plt.title("Candidate-wise Test Accuracy Across Datasets")
    plt.xticks(x + width * (len(all_cand_accs) - 1) / 2, all_candidates, rotation=45)
    plt.legend()
    plt.tight_layout()
    plt.grid(axis='y', linestyle='--', alpha=0.7)
    plt.show()

plot_all_candidate_accuracies(all_candidate_accuracies)